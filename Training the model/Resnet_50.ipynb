{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vOrgkcjAIGTR"
      },
      "outputs": [],
      "source": [
        "#training for 20-50 ages\n",
        "# Install Kaggle package\n",
        "!pip install -q kaggle\n",
        "\n",
        "# Upload your Kaggle API JSON file\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "\n",
        "# Create a directory for Kaggle and move your kaggle.json file there\n",
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# Download the dataset from Kaggle (Replace <dataset-identifier> with the actual dataset identifier)\n",
        "!kaggle datasets download -d mariafrenti/age-prediction\n",
        "\n",
        "# Unzip the dataset (Replace <dataset-name>.zip with the actual zip file name)\n",
        "!unzip age-prediction.zip\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import ResNet50, EfficientNetB0\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import os\n",
        "from glob import glob\n",
        "\n",
        "# Paths to the dataset\n",
        "train_dir = '/content/20-50/20-50/train'  # Replace with actual train directory path\n",
        "test_dir = '/content/20-50/20-50/test'    # Replace with actual test directory path\n",
        "\n",
        "# Count the number of images in the dataset\n",
        "num_train_images = len(glob(train_dir + '/*/*.jpg'))\n",
        "num_test_images = len(glob(test_dir + '/*/*.jpg'))\n",
        "print(f\"Number of training images: {num_train_images}\")\n",
        "print(f\"Number of testing images: {num_test_images}\")\n",
        "\n",
        "# Data generators for training and testing\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, horizontal_flip=True, validation_split=0.2)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='sparse',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='sparse',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='sparse'\n",
        ")\n",
        "# Choose between ResNet50 or EfficientNetB0\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "# or\n",
        "#base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze the layers of the base model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add custom layers on top of the base model\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "predictions = Dense(1)(x)\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "model.summary()\n",
        "# Model checkpoint to save best weights\n",
        "checkpoint = ModelCheckpoint('best_model.weights.h5', monitor='val_mae', save_best_only=True, save_weights_only=True)\n",
        "\n",
        "# Early stopping to prevent overfitting\n",
        "early_stopping = EarlyStopping(monitor='val_mae', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=validation_generator,\n",
        "    epochs=3,\n",
        "    callbacks=[checkpoint, early_stopping]\n",
        ")\n",
        "\n",
        "# Load the best weights\n",
        "model.load_weights('best_model.weights.h5')\n",
        "# Evaluate the model on the test set\n",
        "# test_loss, test_mae = model.evaluate(test_generator, verbose=1)\n",
        "# print(f'Test Loss: {test_loss}')\n",
        "# print(f'Test MAE: {test_mae}')\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(test_generator)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)  # If your predictions are probabilities, get the class with the highest probability\n",
        "\n",
        "# Get true labels from the test set\n",
        "y_true = test_generator.classes\n",
        "\n",
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred_classes)\n",
        "\n",
        "# Plot confusion matrix\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=test_generator.class_indices.keys())\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.show()\n",
        "from google.colab import files\n",
        "model.save('age_prediction_model_resnet2.keras')\n",
        "# Download the model file\n",
        "files.download('age_prediction_model_resnet2.keras')\n",
        "model.save('age_prediction_model_resnet2.h5')\n",
        "# Download the model file\n",
        "files.download('age_prediction_model_resnet2.h5')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#training the combined model for 1-19\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "#for ages 1-19\n",
        "# Install Kaggle package\n",
        "#!pip install -q kaggle\n",
        "\n",
        "# Upload your Kaggle API JSON file\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "\n",
        "# Create a directory for Kaggle and move your kaggle.json file there\n",
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# Download the dataset from Kaggle (Replace <dataset-identifier> with the actual dataset identifier)\n",
        "!kaggle datasets download -d felixjoseph7/Age-data-1-19\n",
        "\n",
        "# Unzip the dataset (Replace <dataset-name>.zip with the actual zip file name)\n",
        "!unzip Age-data-1-19.zip\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGpzbCd0IWP9",
        "outputId": "6ee9db40-82d1-4aeb-e526-b1ae57eb628e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load your existing model trained on ages 20-50\n",
        "model = load_model('age_prediction_model_resnet2.keras')\n"
      ],
      "metadata": {
        "id": "Voc61bkNIhn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths to the new dataset (ages 1-19)\n",
        "train_dir_1_19 = '/content/1-19/train'  # Replace with actual train directory path\n",
        "test_dir_1_19 = '/content/1-19/test'    # Replace with actual test directory path\n",
        "\n",
        "# Create data generators for the new dataset\n",
        "train_datagen_1_19 = ImageDataGenerator(rescale=1./255, horizontal_flip=True, validation_split=0.2)\n",
        "test_datagen_1_19 = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator_1_19 = train_datagen_1_19.flow_from_directory(\n",
        "    train_dir_1_19,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='sparse',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "validation_generator_1_19 = train_datagen_1_19.flow_from_directory(\n",
        "    train_dir_1_19,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='sparse',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "test_generator_1_19 = test_datagen_1_19.flow_from_directory(\n",
        "    test_dir_1_19,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='sparse'\n",
        ")\n"
      ],
      "metadata": {
        "id": "VQV815tXKOED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model checkpoint to save best weights during fine-tuning\n",
        "checkpoint_1_19 = ModelCheckpoint('best_model_1_19.weights.keras', monitor='val_mae', save_best_only=True, save_weights_only=True)\n",
        "\n",
        "# Fine-tune the model on the ages 1-19 dataset\n",
        "history_1_19 = model.fit(\n",
        "    train_generator_1_19,\n",
        "    validation_data=validation_generator_1_19,\n",
        "    epochs=5,  # Increase if needed\n",
        "    callbacks=[checkpoint_1_19, EarlyStopping(monitor='val_mae', patience=3, restore_best_weights=True)]\n",
        ")\n",
        "\n",
        "# Load the best weights from this fine-tuning stage\n",
        "model.load_weights('best_model_1_19.weights.keras')\n"
      ],
      "metadata": {
        "id": "WD2NAwI9KSRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Recreate the data generators for ages 20-50 to mix with the new dataset\n",
        "train_generator_20_50 = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='sparse',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "validation_generator_20_50 = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='sparse',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "# Fine-tune the model on the combined dataset (ages 1-50)\n",
        "history_combined = model.fit(\n",
        "    train_generator_20_50,\n",
        "    validation_data=validation_generator_20_50,\n",
        "    epochs=5,  # Continue training for a few more epochs\n",
        "    callbacks=[checkpoint_1_19, EarlyStopping(monitor='val_mae', patience=3, restore_best_weights=True)]\n",
        ")\n"
      ],
      "metadata": {
        "id": "C4lJu1gDKU2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the updated model\n",
        "model.save('age_prediction_model_combined50.keras')\n",
        "files.download('age_prediction_model_combined50.keras')\n"
      ],
      "metadata": {
        "id": "IDERRclGKXAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on the new test set (ages 1-19)\n",
        "test_loss_1_19, test_mae_1_19 = model.evaluate(test_generator_1_19)\n",
        "print(f'Test Loss (ages 1-19): {test_loss_1_19}')\n",
        "print(f'Test MAE (ages 1-19): {test_mae_1_19}')\n",
        "\n",
        "# Evaluate on the original test set (ages 20-50)\n",
        "test_loss_20_50, test_mae_20_50 = model.evaluate(test_generator_20_50)\n",
        "print(f'Test Loss (ages 20-50): {test_loss_20_50}')\n",
        "print(f'Test MAE (ages 20-50): {test_mae_20_50}')\n"
      ],
      "metadata": {
        "id": "B_x7-ICjKXws"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}